{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.402690400Z",
     "start_time": "2025-05-06T05:07:49.517863500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Metaheuristicas.fitness_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "aa2b839a0ac12d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.522272200Z",
     "start_time": "2025-05-06T05:07:51.400640800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load_and_preprocess_data(filename='Resources/SeisBenchV1_v1_1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "ca4c77e3ca5f4f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.638008500Z",
     "start_time": "2025-05-06T05:07:51.527350Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Metaheuristicas.Genetico import genetic_algorithm\n",
    "\n",
    "mutation = 0.1\n",
    "crossover = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "2ce64b262c9dee2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.663803300Z",
     "start_time": "2025-05-06T05:07:51.643279Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Step 1: Initialize empty DataFrames for each classifier with metrics as columns\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\"]\n",
    "\n",
    "naive_bayes_df = pd.DataFrame(columns=metrics, index=[\"Mutual Information\", \"X2\", \"Relief\"])\n",
    "random_forest_df = pd.DataFrame(columns=metrics, index=[\"Mutual Information\", \"X2\", \"Relief\"])\n",
    "neural_network_df = pd.DataFrame(columns=metrics, index=[\"Mutual Information\", \"X2\", \"Relief\"])\n",
    "\n",
    "# Display all tables function\n",
    "def display_tables():\n",
    "    clear_output(wait=True)\n",
    "    print(\"Naive Bayes Results\")\n",
    "    display(naive_bayes_df)\n",
    "    print(\"Random Forest Results\")\n",
    "    display(random_forest_df)\n",
    "    print(\"Neural Network Results\")\n",
    "    display(neural_network_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "3300486a09ef5141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.728011Z",
     "start_time": "2025-05-06T05:07:51.653509700Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_result(classifier, fitness_function, accuracy, precision, recall, f1_score, auc):\n",
    "    new_data = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "\n",
    "    if classifier == \"Naive Bayes\":\n",
    "        global naive_bayes_df\n",
    "        naive_bayes_df.loc[fitness_function] = new_data\n",
    "    elif classifier == \"Random Forest\":\n",
    "        global random_forest_df\n",
    "        random_forest_df.loc[fitness_function] = new_data\n",
    "    elif classifier == \"Neural Network\":\n",
    "        global neural_network_df\n",
    "        neural_network_df.loc[fitness_function] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "4f12bb4cef31e66b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.813242700Z",
     "start_time": "2025-05-06T05:07:51.728011Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c043203d125fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "28145e55a86c32c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:51.877450700Z",
     "start_time": "2025-05-06T05:07:51.799619700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#dataset split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3839b4e789bb6ed9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "76522f9a0cea930c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:52.576349100Z",
     "start_time": "2025-05-06T05:07:51.873281900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "DT = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ae564958ae401",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "da7d0eb1819d98c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:52.602626600Z",
     "start_time": "2025-05-06T05:07:52.576349100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# print the features avaiable\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "b72de2d61e595b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:52.785569700Z",
     "start_time": "2025-05-06T05:07:52.591789300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seleccionar_caracteristicas(df, indices):\n",
    "    prefijos = [f\"f{n}_\" for n in indices]\n",
    "    columnas_seleccionadas = [col for col in df.columns if any(col.startswith(prefijo) for prefijo in prefijos)]\n",
    "    return df[columnas_seleccionadas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "963dfb44666e2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:52.927399600Z",
     "start_time": "2025-05-06T05:07:52.789866800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def seleccionar_caracteristicas(df, indices):\n",
    "#     return [col for col in df.columns if any(col.startswith(f\"f{n}_\") for n in indices)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92685190233557f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "2feb333aedcf7226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:52.997052700Z",
     "start_time": "2025-05-06T05:07:52.935179700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GaMiFtIndices = [2, 3, 5, 6, 7, 9, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25,\n",
    "                  27, 30, 32, 34, 36, 37,38, 40, 42, 43, 44, 46, 48, 50, 51, 52, 55,\n",
    "                    58, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83\n",
    "]\n",
    "GaX2FtIndices = [9, 11, 12, 13, 16, 19, 21, 23, 28, 30, 34,38, 39, 40, 48, 55, 58, 59, 60, 61, 65, 66,70, 71, 72, 74, 75, 76, 77, 84]\n",
    "GaReliefFFtIndices = [2, 4, 9, 11, 14, 16, 17, 19, 21, 23, 25, 27,38, 39, 42, 49, 55, 58, 62, 64, 65, 66, 67,69, 71, 72, 76, 78, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "1ec1ee062bbacc40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:53.082787600Z",
     "start_time": "2025-05-06T05:07:53.000617Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_GaMiFt = seleccionar_caracteristicas(X_train,GaMiFtIndices)\n",
    "X_train_GaX2Ft = seleccionar_caracteristicas(X_train, GaX2FtIndices)\n",
    "X_train_GaReliefFFt = seleccionar_caracteristicas(X_train, GaReliefFFtIndices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "896e3f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "features = [\n",
    "    'f3', 'f5', 'f6', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f17', 'f18', 'f21',\n",
    "    'f23', 'f24', 'f25', 'f26', 'f28', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36',\n",
    "    'f37', 'f38', 'f39', 'f40', 'f41', 'f44', 'f45', 'f46', 'f49', 'f53', 'f56', 'f57',\n",
    "    'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f84'\n",
    "]\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db9719b040b775",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "23c6b1b1a81bc43f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:53.146791700Z",
     "start_time": "2025-05-06T05:07:53.074517200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CsMiFtIndices = [3, 5, 6, 10, 11, 12, 13, 14, 15, 17, 18, 21,23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35,\n",
    "                 36, 37, 38, 39, 40, 41, 44, 45, 46, 49, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,84\n",
    "\n",
    "]\n",
    "CsX2FtIndices = [1, 7, 10, 19, 20, 24, 26, 27, 30, 32, 34, 37,38, 42, 58, 60, 61, 64, 65, 67, 68, 69, 72, 77]\n",
    "CsReliefFFtIndices = [4, 6, 7, 10, 13, 15, 19, 22, 23, 29, 33, 39,42, 50, 55, 57, 58, 59, 62, 63, 64, 65, 67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "4f6918b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "len(CsMiFtIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "dfddf2148dc94a71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:07:53.245241800Z",
     "start_time": "2025-05-06T05:07:53.144282600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_CsMiFt = seleccionar_caracteristicas(X_train,CsMiFtIndices)\n",
    "X_train_CsX2Ft = seleccionar_caracteristicas(X_train, CsX2FtIndices)\n",
    "X_train_CsReliefFFt = seleccionar_caracteristicas(X_train, CsReliefFFtIndices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00ccb54008a2d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "2207cd59d44095db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:08:05.274997900Z",
     "start_time": "2025-05-06T05:07:53.221047100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "6af2a17acab866ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:16:11.548757700Z",
     "start_time": "2025-05-06T05:16:11.367680500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_naive_bayes_with_kfold(X_train, y_train, k=10, holdout=None, y_test=None):\n",
    "    # Lists to store metrics during cross-validation\n",
    "    accuracies, precisions, recalls, f1s, aucs = [], [], [], [], []\n",
    "    best_f1 = -1\n",
    "    best_model = None\n",
    "\n",
    "    if k > 1:\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=30)\n",
    "        # Perform k-Fold Cross-Validation\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "            # Run it with Naive Bayes\n",
    "            NB.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = NB.predict(X_val_fold)\n",
    "    \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "            precision = precision_score(y_val_fold, y_pred)\n",
    "            recall = recall_score(y_val_fold, y_pred)\n",
    "            f1 = f1_score(y_val_fold, y_pred)\n",
    "            auc = roc_auc_score(y_val_fold, y_pred)\n",
    "    \n",
    "            # Append metrics to lists\n",
    "            accuracies.append(accuracy)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            aucs.append(auc)\n",
    "\n",
    "            # Update the best model based on F1 score\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = NB\n",
    "    \n",
    "        # Calculate mean and std for each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1s)\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1s)\n",
    "        std_auc = np.std(aucs)\n",
    "        # Add results to DataFrame\n",
    "        add_result(\"Naive Bayes\", \"Mutual Information\", mean_accuracy, mean_precision, mean_recall, mean_f1, mean_auc)\n",
    "    \n",
    "        # Print metrics\n",
    "        print(f\"F1 Score: {mean_f1:.3f} $\\pm$ {std_f1:.3f}\")\n",
    "        print(f\"Accuracy: {mean_accuracy:.3f} $\\pm$ {std_accuracy:.3f}\")\n",
    "        print(f\"Precision: {mean_precision:.3f} $\\pm$ {std_precision:.3f}\")\n",
    "        print(f\"Recall: {mean_recall:.3f} $\\pm$ {std_recall:.3f}\")\n",
    "        print(f\"AUC: {mean_auc:.3f} $\\pm$ {std_auc:.3f}\")\n",
    "    \n",
    "        NBMIScores = [accuracies, precisions, recalls, f1s, aucs]\n",
    "        NBMISTD = [std_accuracy, std_precision, std_recall, std_f1, std_auc]\n",
    "        return NBMIScores, NBMISTD, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "554372697b5ca9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:08:05.370959500Z",
     "start_time": "2025-05-06T05:08:05.296716900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_random_forest_with_kfold(X_train, y_train, k=10, holdout=None, y_test=None):\n",
    "\n",
    "    # Lists to store metrics during cross-validation\n",
    "    accuracies, precisions, recalls, f1s, aucs = [], [], [], [], []\n",
    "    best_f1 = -1\n",
    "    best_model = None\n",
    "\n",
    "    # Perform k-Fold Cross-Validation\n",
    "    if k > 1:\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=30)\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "            # Train the Random Forest model\n",
    "            DT.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = DT.predict(X_val_fold)\n",
    "    \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "            precision = precision_score(y_val_fold, y_pred)\n",
    "            recall = recall_score(y_val_fold, y_pred)\n",
    "            f1 = f1_score(y_val_fold, y_pred)\n",
    "            auc = roc_auc_score(y_val_fold, y_pred)\n",
    "    \n",
    "            # Append metrics to lists\n",
    "            accuracies.append(accuracy)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            aucs.append(auc)\n",
    "\n",
    "            # Update the best model based on F1 score\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = DT\n",
    "    \n",
    "        # Calculate mean and std for each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1s)\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1s)\n",
    "        std_auc = np.std(aucs)\n",
    "    \n",
    "        # Print metrics\n",
    "        print(f\"F1 Score: {mean_f1:.3f} $\\pm$ {std_f1:.3f}\")\n",
    "        print(f\"Accuracy: {mean_accuracy:.3f} $\\pm$ {std_accuracy:.3f}\")\n",
    "        print(f\"Precision: {mean_precision:.3f} $\\pm$ {std_precision:.3f}\")\n",
    "        print(f\"Recall: {mean_recall:.3f} $\\pm$ {std_recall:.3f}\")\n",
    "        print(f\"AUC: {mean_auc:.3f} $\\pm$ {std_auc:.3f}\")\n",
    "        # Add results to DataFrame\n",
    "        add_result(\"Random Forest\", \"Mutual Information\", mean_accuracy, mean_precision, mean_recall, mean_f1, mean_auc)\n",
    "    \n",
    "        # Return scores, standard deviations, and the best model\n",
    "        RfMIScores = [accuracies, precisions, recalls, f1s, aucs]\n",
    "        RfMISTD = [std_accuracy, std_precision, std_recall, std_f1, std_auc]\n",
    "        return RfMIScores, RfMISTD, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "86005e498b2c1ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:15:42.449396900Z",
     "start_time": "2025-05-06T05:15:42.438871200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_neural_network_with_kfold(X_train, y_train, k=10, plot=False):\n",
    "    # Lists to store metrics during cross-validation\n",
    "    accuracies, precisions, recalls, f1s, aucs = [], [], [], [], []\n",
    "    best_model = None\n",
    "    best_f1 = -1  # Initialize with a very low value\n",
    "    train_losses, val_losses = [], []  # To store training and validation losses for each fold\n",
    "\n",
    "    # Perform k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=13)\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Define a new model in each fold\n",
    "        input_dim = X_train_fold.shape[1]\n",
    "        model = Sequential([\n",
    "            Input(shape=(input_dim,)),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "        # Train the model on the fold\n",
    "        history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold),\n",
    "                            epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "        # Store training and validation losses\n",
    "        train_losses.append(history.history['loss'])\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "\n",
    "        y_pred_prob = model.predict(X_val_fold, verbose=0)\n",
    "        y_pred_prob = y_pred_prob.flatten()  # Flatten the predictions array\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        f1 = f1_score(y_val_fold, y_pred)\n",
    "        f1s.append(f1)\n",
    "        accuracies.append(accuracy_score(y_val_fold, y_pred))\n",
    "        precisions.append(precision_score(y_val_fold, y_pred))\n",
    "        recalls.append(recall_score(y_val_fold, y_pred))\n",
    "        aucs.append(roc_auc_score(y_val_fold, y_pred_prob))\n",
    "\n",
    "        # Keep the best model based on F1 score\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = model\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    std_precision = np.std(precisions)\n",
    "    std_recall = np.std(recalls)\n",
    "    std_f1 = np.std(f1s)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"F1 Score: {mean_f1:.3f} $\\pm$ {std_f1:.3f}\")\n",
    "    print(f\"Accuracy: {mean_accuracy:.3f} $\\pm$ {std_accuracy:.3f}\")\n",
    "    print(f\"Precision: {mean_precision:.3f} $\\pm$ {std_precision:.3f}\")\n",
    "    print(f\"Recall: {mean_recall:.3f} $\\pm$ {std_recall:.3f}\")\n",
    "    print(f\"AUC: {mean_auc:.3f} $\\pm$ {std_auc:.3f}\")\n",
    "\n",
    "    # Add results to DataFrame\n",
    "    add_result(\"Neural Network\", \"Mutual Information\", mean_accuracy, mean_precision, mean_recall, mean_f1, mean_auc)\n",
    "\n",
    "    # Plot average training and validation losses if plot is True\n",
    "    if plot:\n",
    "        avg_train_loss = np.mean(train_losses, axis=0)\n",
    "        avg_val_loss = np.mean(val_losses, axis=0)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(avg_train_loss, label='Average Training Loss')\n",
    "        plt.plot(avg_val_loss, label='Average Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss Across Folds')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    NN_MIScores = [accuracies, precisions, recalls, f1s, aucs]\n",
    "    NN_MISTD = [std_accuracy, std_precision, std_recall, std_f1, std_auc]\n",
    "    return NN_MIScores, NN_MISTD, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c2c6718d204cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c36a80531d22e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b5e743596b05b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GA Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "73fde5bb2493208a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:08:05.640662800Z",
     "start_time": "2025-05-06T05:08:05.436516100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "ResultsNBGAMI, STDResultsNBGAMI, BestGAMINB= evaluate_naive_bayes_with_kfold(X_train_GaMiFt, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "a9b0b3b3ea88d060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:08:08.706424200Z",
     "start_time": "2025-05-06T05:08:05.637625700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Random Forest\n",
    "ResultsRFGAMI, STDResultsRFGMI, BestGAMIRF= evaluate_random_forest_with_kfold(X_train_GaMiFt, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "e6df7a8cdd79076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:09:10.560452900Z",
     "start_time": "2025-05-06T05:08:08.705413700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Neural Network\n",
    "ResultsNNGAMI, STDResultsNNGAMI, BestGAMINN= evaluate_neural_network_with_kfold(X_train_GaMiFt, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf179474aedfe396",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GA X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "bc616912431ef8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:09:10.761421300Z",
     "start_time": "2025-05-06T05:09:10.551621100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "ResultsNBGAX2, STDResultsNBGAX2, BestGAX2NB= evaluate_naive_bayes_with_kfold(X_train_GaX2Ft, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "dc3ad8ce6e775766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:09:14.460661700Z",
     "start_time": "2025-05-06T05:09:10.682697900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Random Forest\n",
    "ResultsRFGAX2, STDResultsRFGAX2, BestGAX2RF= evaluate_random_forest_with_kfold(X_train_GaX2Ft, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "eec0555de14b711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:10:15.713882900Z",
     "start_time": "2025-05-06T05:09:14.460661700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Neural Network\n",
    "ResultsNNGAX2, STDResultsNNGAX2, BestGAX2NN= evaluate_neural_network_with_kfold(X_train_GaX2Ft, y_train, k=10, plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604308d06f14511e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### GA ReliefF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "464c6aee6ae2dc34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:16:31.384915700Z",
     "start_time": "2025-05-06T05:16:30.167079200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "ResultsNBGAReliefF, STDResultsNBGAReliefF, BestGARFNB= evaluate_naive_bayes_with_kfold(X_train_GaReliefFFt, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "ad73e1d7b00470b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:16:33.626781100Z",
     "start_time": "2025-05-06T05:16:30.322760600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Random Forest\n",
    "ResultsRFGAReliefF, STDResultsRFGAReliefF, BestGARFRF= evaluate_random_forest_with_kfold(X_train_GaReliefFFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "8f1d002d2b8dd6da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:17:31.796242200Z",
     "start_time": "2025-05-06T05:16:33.630054700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Neural Network\n",
    "ResultsNNGAReliefF, STDResultsNNGAReliefF, BestGARFNB= evaluate_neural_network_with_kfold(X_train_GaReliefFFt, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839c22bf0702995",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005a041dac1fa1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CS Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "c590607ea4bd48c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:17:31.909599800Z",
     "start_time": "2025-05-06T05:17:31.776183100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "ResultsNBCSMI, STDResultsNBCSMI, BestCSMINB= evaluate_naive_bayes_with_kfold(X_train_CsMiFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "ce166fa5ebfeba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:17:34.916299500Z",
     "start_time": "2025-05-06T05:17:31.910601900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Random Forest\n",
    "ResultsRFCsMI, STDResultsRFCsMI, BestCSMIRF= evaluate_random_forest_with_kfold(X_train_CsMiFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "7d37979e67cc8859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:18:34.496568300Z",
     "start_time": "2025-05-06T05:17:34.917697400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Neural Network\n",
    "ResultsNNCsMI, STDResultsNNCsMI, BestCSMINN= evaluate_neural_network_with_kfold(X_train_CsMiFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ffae583a6883e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CS X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "189e8e554b5974b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:18:34.611368400Z",
     "start_time": "2025-05-06T05:18:34.486555100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "ResultsNBCSX2, STDResultsNBCSX2, BestCSX2NB= evaluate_naive_bayes_with_kfold(X_train_CsX2Ft, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "eb6a1ed61ec3ee98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:18:37.169501300Z",
     "start_time": "2025-05-06T05:18:34.611368400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Random Forest\n",
    "ResultsRFCsX2, STDResultsRFCsX2, BestCSX2RF= evaluate_random_forest_with_kfold(X_train_CsX2Ft, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "e3236670599c05d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:19:39.463908600Z",
     "start_time": "2025-05-06T05:18:37.169501300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Neural Network\n",
    "ResultsNNCsX2, STDResultsNNCsX2, BestCSX2NN= evaluate_neural_network_with_kfold(X_train_CsX2Ft, y_train, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234c5e1df936050",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CS ReliefF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "757a7567f8545430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:19:39.544764200Z",
     "start_time": "2025-05-06T05:19:39.461367600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "ResultsNBCsReliefF, STDResultsNBCsReliefF, BestCSRFNB= evaluate_naive_bayes_with_kfold(X_train_CsReliefFFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "e534b1fbb08a48ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:19:41.650751Z",
     "start_time": "2025-05-06T05:19:39.545760400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Random Forest\n",
    "ResultsRFCsReliefF, STDResultsRFCsReliefF, BestCSRFRF= evaluate_random_forest_with_kfold(X_train_CsReliefFFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "aaccdac7e83e1a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.056176600Z",
     "start_time": "2025-05-06T05:19:41.649750500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Neural Network\n",
    "ResultsNNCsReliefF, STDResultsNNCsReliefF, BestCSRFNN= evaluate_neural_network_with_kfold(X_train_CsReliefFFt, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f778f493e8774",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ALL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "7bc77777929d6ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.056176600Z",
     "start_time": "2025-05-06T05:20:37.050290400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# ResultsNBAll, STDResultsNBAll= evaluate_naive_bayes_with_kfold(X_train, y_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "29f7635b57eb5308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.178817700Z",
     "start_time": "2025-05-06T05:20:37.058783300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "# ResultsRFAll, STDResultsRFAll= evaluate_random_forest_with_kfold(X_train, y_train, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "c859b43de6e83980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.249837300Z",
     "start_time": "2025-05-06T05:20:37.180817900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "# ResultsNNAll, STDResultsNNAll= evaluate_neural_network_with_kfold(X_train, y_train, k=10)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8973b6b711abc8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "cd5655e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.398076200Z",
     "start_time": "2025-05-06T05:20:37.324594600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "results = [\n",
    "    # GAMI\n",
    "    ResultsNBGAMI, ResultsRFGAMI, ResultsNNGAMI,\n",
    "    # GAX2\n",
    "    ResultsNBGAX2, ResultsRFGAX2, ResultsNNGAX2,\n",
    "    # GAReliefF\n",
    "    ResultsNBGAReliefF, ResultsRFGAReliefF, ResultsNNGAReliefF,\n",
    "    # CsMI\n",
    "    ResultsNBCSMI, ResultsRFCsMI, ResultsNNCsMI,\n",
    "    # CsX2\n",
    "    ResultsNBCSX2, ResultsRFCsX2, ResultsNNCsX2,\n",
    "    # CsReliefF\n",
    "    ResultsNBCsReliefF, ResultsRFCsReliefF, ResultsNNCsReliefF,\n",
    "    # # All features\n",
    "    # ResultsNBAll, ResultsRFAll, ResultsNNAll\n",
    "]\n",
    "\n",
    "best_f1_avg = max(np.mean(results[i][3]) for i in range(len(results)))\n",
    "print(\"Best F1 Score Average (excluding all features): \", best_f1_avg)\n",
    "\n",
    "# Find the index of the list containing the best F1 average\n",
    "best_f1_avg_index = next(i for i in range(len(results)) if np.mean(results[i][3]) == best_f1_avg)\n",
    "print(\"Best F1 Score Average belongs to list index (excluding all features): \", best_f1_avg_index)\n",
    "result_names = [\n",
    "    \"ResultsNBGAMI\", \"ResultsRFGAMI\", \"ResultsNNGAMI\",\n",
    "    \"ResultsNBGAX2\", \"ResultsRFGAX2\", \"ResultsNNGAX2\",\n",
    "    \"ResultsNBGAReliefF\", \"ResultsRFGAReliefF\", \"ResultsNNGAReliefF\",\n",
    "    \"ResultsNBCSMI\", \"ResultsRFCsMI\", \"ResultsNNCsMI\",\n",
    "    \"ResultsNBCSX2\", \"ResultsRFCsX2\", \"ResultsNNCsX2\",\n",
    "    \"ResultsNBCsReliefF\", \"ResultsRFCsReliefF\", \"ResultsNNCsReliefF\"\n",
    "]\n",
    "\n",
    "print(\"Result Names:\")\n",
    "for i, name in enumerate(result_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "\n",
    "\n",
    "average_f1_scores = [np.mean(result[3]) for result in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "3480ebef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.474601900Z",
     "start_time": "2025-05-06T05:20:37.397078300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "np.mean(ResultsNNCsMI[3]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "2cc00061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create a DataFrame to store F1 scores for each fold\n",
    "f1_scores_table = pd.DataFrame()\n",
    "\n",
    "# Iterate through the results and extract F1 scores\n",
    "for i, result in enumerate(results):\n",
    "    f1_scores_table[f\"Model {i}\"] = result[3]  # F1 scores are at index 3\n",
    "\n",
    "# Display the table\n",
    "f1_scores_table.index.name = \"Fold\"\n",
    "f1_scores_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "30569785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:37.565348200Z",
     "start_time": "2025-05-06T05:20:37.469616700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "average_f1_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf0cc0",
   "metadata": {},
   "source": [
    "# P-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "8c489643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'results' is a list of model results where each contains F1 scores at index 3\n",
    "pivot_index = 11  # ResultsNNCsMI\n",
    "pivot_model = results[pivot_index][3]  # Extract F1 scores from index 3\n",
    "\n",
    "print(f\"Comparing pivot model (results[{pivot_index}]) to others:\\n\")\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "comparison_results = []\n",
    "\n",
    "for i, model_scores in enumerate(results):\n",
    "    if i == pivot_index:\n",
    "        continue\n",
    "\n",
    "    model_f1_scores = model_scores[3]  # F1 scores are at index 3 in each result\n",
    "    \n",
    "    # Make sure both arrays have the same length\n",
    "    min_length = min(len(pivot_model), len(model_f1_scores))\n",
    "    if len(pivot_model) != len(model_f1_scores):\n",
    "        print(f\"Warning: Length mismatch for model {i}. Truncating to {min_length} samples.\")\n",
    "        x = pivot_model[:min_length]\n",
    "        y = model_f1_scores[:min_length]\n",
    "    else:\n",
    "        x = pivot_model\n",
    "        y = model_f1_scores\n",
    "    \n",
    "    # Check if there are enough non-zero differences for the test\n",
    "    differences = np.array(x) - np.array(y)\n",
    "    non_zero_diffs = differences[differences != 0]\n",
    "    \n",
    "    if len(non_zero_diffs) < 6:  # Wilcoxon test requires at least 6 non-zero differences for reliability\n",
    "        print(f\"Model Index {i}: Insufficient non-zero differences ({len(non_zero_diffs)}), skipping test\")\n",
    "        p_value_formatted = \"N/A\"\n",
    "        significance = \"Insufficient data\"\n",
    "    else:\n",
    "        try:\n",
    "            # In newer scipy versions, wilcoxon returns a tuple (statistic, pvalue)\n",
    "            result = wilcoxon(x, y)\n",
    "            if isinstance(result, tuple):\n",
    "                stat, p = result\n",
    "            else:\n",
    "                # For older scipy versions that might return just the statistic\n",
    "                p = result\n",
    "                stat = None\n",
    "                \n",
    "            significance = \"Significant\" if p < 0.05 else \"Not Significant\"\n",
    "            p_value_formatted = f\"p < 0.05\" if p < 0.050 else f\"p = {p:.3f}\"\n",
    "            print(f\"Model Index {i}: {p_value_formatted}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model Index {i}: Error in Wilcoxon test - {str(e)}\")\n",
    "            p_value_formatted = f\"Error: {str(e)}\"\n",
    "            significance = \"Error\"\n",
    "    \n",
    "    comparison_results.append({\n",
    "        \"Model Index\": i,\n",
    "        # \"Model Name\": f\"Model {i}\" if i < len(results) and len(results[i]) > 0 and isinstance(results[i][0], str) else f\"Model {i}\",\n",
    "        \"Model Name\": result_names[i] if i < len(result_names) else f\"Model {i}\",\n",
    "        \"p-value\": p_value_formatted,\n",
    "        \"Significance\": significance\n",
    "    })\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# # Sort by significance and p-value for better readability\n",
    "# comparison_df = comparison_df.sort_values(by=[\"Significance\", \"p-value\"], \n",
    "#                                          key=lambda x: pd.Categorical(x[\"Significance\"], \n",
    "#                                                                     categories=[\"Significant\", \"Not Significant\", \"Insufficient data\", \"Error\"], \n",
    "#                                                                     ordered=True))\n",
    "\n",
    "print(\"\\nSummary of comparison results:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# comparison_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "\n",
    "# The DataFrame can be displayed in a notebook or returned from a function\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "5bdf5af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:50:18.468687900Z",
     "start_time": "2025-05-08T20:50:18.428483900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "pivot_index = 11  # ResultsNNCsMI\n",
    "pivot_model = results[pivot_index][3]  # Extract F1 scores from index 3\n",
    "\n",
    "print(f\"Comparing pivot model (results[{pivot_index}]) to others:\\n\")\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "comparison_results = pd.DataFrame(columns=[\"Model Index\", \"p-value\", \"Significance\"])\n",
    "for i, model_scores in enumerate(results):\n",
    "    if i == pivot_index:\n",
    "        continue\n",
    "\n",
    "    model_f1_scores = model_scores[3]  # F1 scores are at index 3 in each result\n",
    "    stat, p = wilcoxon(pivot_model, model_f1_scores)\n",
    "    significance = \"Significant\" if p < 0.05 else \"Not Significant\"\n",
    "    p_value_formatted = f\"p $<$ 0.05\" if p < 0.050 else f\"p $=$ {p:.3f}\"\n",
    "    print(f\"Model Index {i}: {p_value_formatted}\")\n",
    "    comparison_results = pd.concat(\n",
    "        [comparison_results, pd.DataFrame({\"Model Index\": [i], \"p-value\": [p_value_formatted], \"Significance\": [significance]})],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# Display the results as a table\n",
    "comparison_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b855cee35040444",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169475d3fe69717",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "run with holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64dcd80835067a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T05:20:38.119479500Z",
     "start_time": "2025-05-06T05:20:37.820017Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test_GaX2Ft = seleccionar_caracteristicas(X_test,GaX2FtIndices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7ae64bc3f8c0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Validation with GA-X2-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9d6a1b48121ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Use the best model from GA-X2-NN\n",
    "best_model = BestGAX2NN\n",
    "\n",
    "# Predict on the holdout data\n",
    "y_pred_prob = best_model.predict(X_test_GaX2Ft)\n",
    "y_pred_holdout = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Evaluate the model on the holdout data\n",
    "accuracy = accuracy_score(y_test, y_pred_holdout)\n",
    "precision = precision_score(y_test, y_pred_holdout)\n",
    "recall = recall_score(y_test, y_pred_holdout)\n",
    "f1 = f1_score(y_test, y_pred_holdout)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)  # Use probabilities for AUC calculation\n",
    "\n",
    "# Print the results\n",
    "print(\"Validation Results with Holdout Data:\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
